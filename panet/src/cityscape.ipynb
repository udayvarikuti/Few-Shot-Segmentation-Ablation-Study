{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36c0c7cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T01:08:17.907905Z",
     "start_time": "2022-06-09T01:08:17.903332Z"
    }
   },
   "outputs": [],
   "source": [
    "import cityscapesscripts.preparation.createTrainIdInstanceImgs as ins\n",
    "import os, glob, sys\n",
    "from cityscapesscripts.helpers.annotation import Annotation\n",
    "from cityscapesscripts.helpers.labels import name2label\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221eabf1",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d12c0147",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T03:29:37.147417Z",
     "start_time": "2022-06-09T03:29:37.117794Z"
    }
   },
   "outputs": [],
   "source": [
    "class Cityscape(Dataset):\n",
    "    def __init__(self, annotation_path, dataset_size, img_transforms=None, mask_transforms=None, n_ways=1,\n",
    "                 n_shots=1, n_queries=1,apply_flip=False):\n",
    "        super().__init__()\n",
    "        self.annotation_path = annotation_path\n",
    "        self.dataset_size = dataset_size\n",
    "        self.label_dict = self.get_label_dict()\n",
    "        self.class_files = self.get_labels_classwise(self)\n",
    "        self.n_ways = n_ways\n",
    "        self.n_shots = n_shots\n",
    "        self.n_queries = n_queries\n",
    "        self.img_transforms = img_transforms\n",
    "        self.mask_transforms = mask_transforms\n",
    "        self.dataset = self.generate_dataset()\n",
    "        \n",
    "    def get_label_dict(self):\n",
    "        labels =  ['road', 'sidewalk', 'building', 'wall', 'fence', 'pole', 'traffic light', 'traffic sign', 'vegetation', 'terrain', 'sky', \n",
    "          'person','rider', 'car', 'truck', 'bus', 'train', 'motorcycle', 'bicycle']\n",
    "        return dict(zip(range(len(labels)), labels))\n",
    "\n",
    "    def get_labels_classwise(self, files):\n",
    "        searchFine = os.path.join(self.annotation_path ,\"gtFine\", \"*\" , \"*\" ,\"*_gt*_polygons.json\")\n",
    "        filesFine = glob.glob(searchFine)\n",
    "        class_files = defaultdict(set)\n",
    "        for f in filesFine:\n",
    "            annotation = Annotation()\n",
    "            annotation.fromJsonFile(f)\n",
    "            for obj in annotation.objects:\n",
    "                if obj.label in list(self.label_dict.values()):\n",
    "                    class_files[obj.label].add(f)\n",
    "        return class_files\n",
    "    \n",
    "    def generate_dataset(self):\n",
    "        dataset = []\n",
    "        for _ in range(self.dataset_size):\n",
    "            sample = {}\n",
    "            self.support_classes = random.choices(list(self.label_dict.values()), k=self.n_ways)\n",
    "            self.query_classes = random.choices(self.support_classes, k=self.n_queries)\n",
    "            \n",
    "            support_labels, query_labels = [], []\n",
    "            for sup_class in self.support_classes:\n",
    "                support_labels.append(random.choices(list(self.class_files[sup_class]), k=self.n_shots))\n",
    "            for que_class in self.query_classes:\n",
    "                query_labels.extend(random.choices(list(self.class_files[que_class]), k=1))\n",
    "            dataset.append(support_labels+query_labels)\n",
    "            \n",
    "        return dataset\n",
    "    \n",
    "    def createLabelImg(self, f, class_label):\n",
    "        annotation = Annotation()\n",
    "        annotation.fromJsonFile(f)\n",
    "        size = (annotation.imgWidth , annotation.imgHeight)\n",
    "        background = name2label['unlabeled'].id\n",
    "        fg_mask = Image.new(\"1\", size, background)\n",
    "        drawer = ImageDraw.Draw(fg_mask)\n",
    "        for obj in annotation.objects:\n",
    "            label = obj.label\n",
    "            if ( not label in name2label ) and label.endswith('group'):\n",
    "                label = label[:-len('group')]\n",
    "            if not label in name2label:\n",
    "                print( \"Label '{}' not known.\".format(label) )\n",
    "            elif obj.label == class_label:\n",
    "                # If the object is deleted, skip it\n",
    "                if obj.deleted or name2label[label].id < 0:\n",
    "                    continue\n",
    "                polygon = obj.polygon\n",
    "                val = name2label[label].id\n",
    "                drawer.polygon(polygon, fill=1)\n",
    "        bg_mask = Image.new(\"1\", size, 1)\n",
    "        bg_mask = np.asarray(bg_mask)\n",
    "        bg_mask[np.array(fg_mask)==1] = 0\n",
    "        return fg_mask, Image.fromarray(bg_mask)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_size\n",
    "    \n",
    "    def get_filename_from_annotation(self, ann_filename):\n",
    "        image_path = os.path.join(self.annotation_path ,\"leftImg8bit\")\n",
    "        ext_path = '/'.join(ann_filename.split('/')[-3:]).replace('gtFine_polygons', 'leftImg8bit').replace('.json'\n",
    "                                                                                                            , '.png')\n",
    "        return image_path + '/' + ext_path\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = {}\n",
    "        shot = {}\n",
    "        support_labels = self.dataset[idx][:-self.n_queries]\n",
    "        query_labels = self.dataset[idx][-self.n_queries:]\n",
    "        \n",
    "        sample['support_images'] = [[self.img_transforms(Image.open(self.get_filename_from_annotation(path)))  \n",
    "                                    for path in label_path] for label_path in support_labels]\n",
    "        sample['query_images'] = [self.img_transforms(Image.open(self.get_filename_from_annotation(label_path)))\n",
    "                                   for label_path in query_labels]\n",
    "        sample['support_mask'] = []\n",
    "        for way in support_labels:\n",
    "            masks = []\n",
    "            for (f, class_label) in zip(way,self.support_classes):\n",
    "                shot['fg_mask'] = self.mask_transforms(self.createLabelImg(f, class_label)[0])\n",
    "                shot['bg_mask'] = self.mask_transforms(self.createLabelImg(f, class_label)[1])\n",
    "                masks.append(shot)\n",
    "            sample['support_mask'].append(masks)\n",
    "                \n",
    "#         sample['support_mask'] = [[shot['fg_mask'] = self.mask_transforms(self.createLabelImg(f, class_label)[0]),\n",
    "#                             shot['bg_mask'] = self.mask_transforms(self.createLabelImg(f, class_label)[1]) \n",
    "#                             for (f, class_label) in zip(way,self.support_classes)] for way in support_labels]\n",
    "        #shot['bg_mask'] = [[self.mask_transforms(self.createLabelImg(f, class_label)[1]) for (f, class_label) in \n",
    "                              #zip(way,self.support_classes)] for way in support_labels]\n",
    "        #sample['support_mask'] = shot\n",
    "        sample['query_labels'] = [self.mask_transforms(self.createLabelImg(f, class_label)[0]) for (f, class_label) in \n",
    "                                   zip(query_labels,self.query_classes)]\n",
    "        \n",
    "#         #Apply Transformations\n",
    "#         if self.transforms is not None:\n",
    "#             sample = self.transforms(sample)\n",
    "#         # Transform to tensor\n",
    "#         if self.to_tensor is not None:\n",
    "#             sample = self.to_tensor(sample)\n",
    "                             \n",
    "        return sample\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "2bfecb5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T03:29:46.841521Z",
     "start_time": "2022-06-09T03:29:37.428168Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose\n",
    "from torchvision import transforms\n",
    "\n",
    "#RandomMirror, Resize, ToTensorNormalize\n",
    "input_size = (417, 417)\n",
    "cityscapesPath = '../../data/Cityscape'\n",
    "dataset_size = 300\n",
    "\n",
    "flip_transform = transforms.RandomHorizontalFlip(p=0.25)\n",
    "img_transforms = Compose([transforms.ToTensor(),\n",
    "                      #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                      transforms.Resize(size=input_size),\n",
    "                      flip_transform])\n",
    "mask_transforms = Compose([transforms.ToTensor(),\n",
    "                      transforms.Resize(size=input_size),\n",
    "                      flip_transform])\n",
    "\n",
    "dataset = Cityscape(cityscapesPath, dataset_size, img_transforms=img_transforms, mask_transforms=mask_transforms,\n",
    "                   n_ways=5, n_shot=2, n_queries=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "affd1237",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T03:29:46.845009Z",
     "start_time": "2022-06-09T03:29:46.842720Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "cdcccd1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T03:29:46.847638Z",
     "start_time": "2022-06-09T03:29:46.845887Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "fe8151a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T03:29:48.600711Z",
     "start_time": "2022-06-09T03:29:46.848999Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "#Prediction \n",
    "idx=0\n",
    "iterator=iter(train_loader)\n",
    "sample=iterator.next()\n",
    "support_img=[[shot for shot in way]\n",
    "                for way in sample['support_images']]\n",
    "fg_mask=[[shot[f'fg_mask'].float() for shot in way]\n",
    "                for way in sample['support_mask']]\n",
    "bg_mask=[[shot[f'bg_mask'].float() for shot in way]\n",
    "                for way in sample['support_mask']]\n",
    "\n",
    "query_img= [query for query in sample['query_images']]\n",
    "query_gt = torch.cat([queryGT.long()\n",
    "                        for queryGT in sample['query_labels']], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7270b96e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
