{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36c0c7cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T04:17:29.343174Z",
     "start_time": "2022-06-09T04:17:28.644299Z"
    }
   },
   "outputs": [],
   "source": [
    "import cityscapesscripts.preparation.createTrainIdInstanceImgs as ins\n",
    "import os, glob, sys\n",
    "from cityscapesscripts.helpers.annotation import Annotation\n",
    "from cityscapesscripts.helpers.labels import name2label\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221eabf1",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d12c0147",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T06:49:41.144566Z",
     "start_time": "2022-06-09T06:49:41.114786Z"
    }
   },
   "outputs": [],
   "source": [
    "class Cityscape(Dataset):\n",
    "    def __init__(self, base_path, dataset_size, labels=None, split='train', img_transforms=None, mask_transforms=None, n_ways=1,\n",
    "                 n_shots=1, n_queries=1,apply_flip=False):\n",
    "        super().__init__()\n",
    "        self.base_path = base_path\n",
    "        self.image_path = os.path.join(self.base_path, 'leftImg8bit', split)\n",
    "        self.annotation_path = os.path.join(self.base_path, 'gtFine', split)\n",
    "        self.labels = list(labels)\n",
    "        self.dataset_size = dataset_size\n",
    "        self.label_dict = self.get_label_dict()\n",
    "        self.class_files = self.get_labels_classwise(self)\n",
    "        self.n_ways = n_ways\n",
    "        self.n_shots = n_shots\n",
    "        self.n_queries = n_queries\n",
    "        self.img_transforms = img_transforms\n",
    "        self.mask_transforms = mask_transforms\n",
    "        self.dataset = self.generate_dataset()\n",
    "        \n",
    "    def get_label_dict(self):\n",
    "        dataset_labels =  ['bicycle', 'sidewalk', 'traffic sign', 'rider','truck','road', 'building', 'wall', 'fence', 'pole', 'traffic light', 'vegetation', 'terrain', 'sky', \n",
    "          'person', 'car', 'truck', 'bus', 'train', 'motorcycle']\n",
    "        return dict(zip(range(len(dataset_labels)), dataset_labels))\n",
    "\n",
    "    def get_labels_classwise(self, files):\n",
    "        searchFine = os.path.join(self.annotation_path, \"*\" ,\"*_gt*_polygons.json\")\n",
    "        filesFine = glob.glob(searchFine)\n",
    "        class_files = defaultdict(set)\n",
    "        if self.labels is not None:\n",
    "            self.selected_labels = {key: self.label_dict[key] for key in self.labels}\n",
    "        else:\n",
    "            self.selected_labels = self.label_dict\n",
    "        for f in filesFine:\n",
    "            annotation = Annotation()\n",
    "            annotation.fromJsonFile(f)\n",
    "            for obj in annotation.objects:\n",
    "                if obj.label in list(self.selected_labels.values()):\n",
    "                    class_files[obj.label].add(f)\n",
    "        return class_files\n",
    "        \n",
    "    def generate_dataset(self):\n",
    "        dataset = []\n",
    "        for _ in range(self.dataset_size):\n",
    "            sample = {}\n",
    "            self.support_classes = random.choices(list(self.selected_labels.values()), k=self.n_ways)\n",
    "            self.query_classes = random.choices(self.support_classes, k=self.n_queries)\n",
    "            \n",
    "            support_labels, query_labels = [], []\n",
    "            for sup_class in self.support_classes:\n",
    "                support_labels.append(random.choices(list(self.class_files[sup_class]), k=self.n_shots))\n",
    "            for que_class in self.query_classes:\n",
    "                query_labels.extend(random.choices(list(self.class_files[que_class]), k=1))\n",
    "            dataset.append(support_labels+query_labels)\n",
    "            \n",
    "        return dataset\n",
    "    \n",
    "    def createLabelImg(self, f, class_label):\n",
    "        annotation = Annotation()\n",
    "        annotation.fromJsonFile(f)\n",
    "        size = (annotation.imgWidth , annotation.imgHeight)\n",
    "        background = name2label['unlabeled'].id\n",
    "        fg_mask = Image.new(\"1\", size, background)\n",
    "        drawer = ImageDraw.Draw(fg_mask)\n",
    "        for obj in annotation.objects:\n",
    "            label = obj.label\n",
    "            if ( not label in name2label ) and label.endswith('group'):\n",
    "                label = label[:-len('group')]\n",
    "            if not label in name2label:\n",
    "                print(\"Label '{}' not known.\".format(label))\n",
    "            elif obj.label == class_label:\n",
    "                # If the object is deleted, skip it\n",
    "                if obj.deleted or name2label[label].id < 0:\n",
    "                    continue\n",
    "                polygon = obj.polygon\n",
    "                val = name2label[label].id\n",
    "                drawer.polygon(polygon, fill=1)\n",
    "        bg_mask = Image.new(\"1\", size, 1)\n",
    "        bg_mask = np.asarray(bg_mask)\n",
    "        bg_mask[np.array(fg_mask)==1] = 0\n",
    "        return fg_mask, Image.fromarray(bg_mask)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_size\n",
    "    \n",
    "    def get_filename_from_annotation(self, ann_filename):\n",
    "        ext_path = '/'.join(ann_filename.split('/')[-2:]).replace('gtFine_polygons', 'leftImg8bit').replace('.json','.png')\n",
    "        return self.image_path + '/' + ext_path\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = {}\n",
    "        shot = {}\n",
    "        support_labels = self.dataset[idx][:-self.n_queries]\n",
    "        query_labels = self.dataset[idx][-self.n_queries:]\n",
    "        \n",
    "        sample['support_images'] = [[self.img_transforms(Image.open(self.get_filename_from_annotation(path)))  \n",
    "                                    for path in label_path] for label_path in support_labels]\n",
    "        sample['query_images'] = [self.img_transforms(Image.open(self.get_filename_from_annotation(label_path)))\n",
    "                                   for label_path in query_labels]\n",
    "        sample['support_mask'] = []\n",
    "        for way in support_labels:\n",
    "            masks = []\n",
    "            for (f, class_label) in zip(way,self.support_classes):\n",
    "                shot['fg_mask'] = self.mask_transforms(self.createLabelImg(f, class_label)[0])\n",
    "                shot['bg_mask'] = self.mask_transforms(self.createLabelImg(f, class_label)[1])\n",
    "                masks.append(shot)\n",
    "            sample['support_mask'].append(masks)\n",
    "                \n",
    "#         sample['support_mask'] = [[shot['fg_mask'] = self.mask_transforms(self.createLabelImg(f, class_label)[0]),\n",
    "#                             shot['bg_mask'] = self.mask_transforms(self.createLabelImg(f, class_label)[1]) \n",
    "#                             for (f, class_label) in zip(way,self.support_classes)] for way in support_labels]\n",
    "        #shot['bg_mask'] = [[self.mask_transforms(self.createLabelImg(f, class_label)[1]) for (f, class_label) in \n",
    "                              #zip(way,self.support_classes)] for way in support_labels]\n",
    "        #sample['support_mask'] = shot\n",
    "        sample['query_labels'] = [self.mask_transforms(self.createLabelImg(f, class_label)[0]) for (f, class_label) in \n",
    "                                   zip(query_labels,self.query_classes)]\n",
    "                             \n",
    "        return sample\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7aea2502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T06:49:41.480067Z",
     "start_time": "2022-06-09T06:49:41.472243Z"
    }
   },
   "outputs": [],
   "source": [
    "CLASS_LABELS = {\n",
    "    'VOC': {\n",
    "        'all': set(range(1, 21)),\n",
    "        0: set(range(1, 21)) - set(range(1, 6)),\n",
    "        1: set(range(1, 21)) - set(range(6, 11)),\n",
    "        2: set(range(1, 21)) - set(range(11, 16)),\n",
    "        3: set(range(1, 21)) - set(range(16, 21)),\n",
    "    },\n",
    "    'COCO': {\n",
    "        'all': set(range(1, 81)),\n",
    "        0: set(range(1, 81)) - set(range(1, 21)),\n",
    "        1: set(range(1, 81)) - set(range(21, 41)),\n",
    "        2: set(range(1, 81)) - set(range(41, 61)),\n",
    "        3: set(range(1, 81)) - set(range(61, 81)),\n",
    "    },\n",
    "    'Cityscape': {\n",
    "        'all': set(range(1, 20)),\n",
    "        0: set(range(6, 20)),\n",
    "        1: set(range(1, 6)),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2bfecb5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T06:49:47.179339Z",
     "start_time": "2022-06-09T06:49:41.635892Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose\n",
    "from torchvision import transforms\n",
    "\n",
    "#RandomMirror, Resize, ToTensorNormalize\n",
    "input_size = (417, 417)\n",
    "cityscapesPath = '../../data/Cityscape'\n",
    "dataset_size = 300\n",
    "\n",
    "flip_transform = transforms.RandomHorizontalFlip(p=0.25)\n",
    "img_transforms = Compose([transforms.ToTensor(),\n",
    "                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                      transforms.Resize(size=input_size),\n",
    "                      flip_transform])\n",
    "mask_transforms = Compose([transforms.ToTensor(),\n",
    "                      transforms.Resize(size=input_size),\n",
    "                      flip_transform])\n",
    "\n",
    "dataset = Cityscape(cityscapesPath, dataset_size, labels=CLASS_LABELS['Cityscape'][0], split='train',img_transforms=img_transforms, mask_transforms=mask_transforms,\n",
    "                   n_ways=2, n_shots=1, n_queries=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "affd1237",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T06:49:47.182726Z",
     "start_time": "2022-06-09T06:49:47.180317Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cdcccd1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T06:49:47.186437Z",
     "start_time": "2022-06-09T06:49:47.183953Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fe8151a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T06:49:47.481428Z",
     "start_time": "2022-06-09T06:49:47.188158Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "#Prediction \n",
    "idx=0\n",
    "iterator=iter(train_loader)\n",
    "sample=iterator.next()\n",
    "support_img=[[shot for shot in way]\n",
    "                for way in sample['support_images']]\n",
    "fg_mask=[[shot[f'fg_mask'].float() for shot in way]\n",
    "                for way in sample['support_mask']]\n",
    "bg_mask=[[shot[f'bg_mask'].float() for shot in way]\n",
    "                for way in sample['support_mask']]\n",
    "\n",
    "query_img= [query for query in sample['query_images']]\n",
    "query_gt = torch.cat([queryGT.long()\n",
    "                        for queryGT in sample['query_labels']], dim=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
