{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prasad/anaconda3/envs/aec/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Lab V3 Encoder for Few Shot Segmentation backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Encoder for few shot segmentation (DeepLabv3)\n",
    "\"\"\"\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #load pretrained model\n",
    "        self.features = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet101', pretrained=True)\n",
    "        self.features.aux_classifier=Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y=self.features(x)['out']\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of FewShot Segmentation Core Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FewShotSeg(nn.Module):\n",
    "    \"\"\"\n",
    "    Fewshot Segmentation model\n",
    "\n",
    "    Args:\n",
    "        in_channels:\n",
    "            number of input channels\n",
    "        pretrained_path:\n",
    "            path of the model for initialization\n",
    "        cfg:\n",
    "            model configurations\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.encoder = Encoder()\n",
    "\n",
    "    def forward(self,Si,fg_mask,bg_mask,Qi):\n",
    "\n",
    "        #get one episode (Si,Qi)\n",
    "        #Si = support images way x shot x [B x 3 x H x W]\n",
    "        #Qi = query images way x shot x [B x 3 x H x W]\n",
    "        #number of classes is the number of ways\n",
    "        c_ways=len(Si)\n",
    "        #number of shots in each class\n",
    "        k_shots=len(Si[0])\n",
    "        batch_size=Si[0][0].shape[0]\n",
    "        img_size=Si[0][0].shape[1:]\n",
    "\n",
    "\n",
    "        #concatenate support and query into a single large tensor\n",
    "\n",
    "        support= [torch.cat(classes,dim=0) for classes in Si]\n",
    "        query  = [torch.cat(Qi,dim=0),]\n",
    "\n",
    "        model_ip= torch.cat(support+query,dim=0)\n",
    "\n",
    "        features=self.encoder(model_ip)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f5c7ac77e593d0994949fe61f06040dedc773eb228097f0a804bc0d2d8d2f83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('aec': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
